mkdir -p __yalla_dir__/HOSTS/


scontrol show hostname $SLURM_NODELIST | awk '{for (i=0;i<32;i++) { print $0}}' > __yalla_dir__/__job_name__machines.txt
split -n __PARALLEL_RUNS__ -d -a 4  __yalla_dir__/__job_name__machines.txt  __yalla_dir__/HOSTS/__job_name__mach
cd __yalla_dir__/HOSTS
sort -u ../__job_name__machines.txt > b
for f in __job_name__mach*; do
    sort -u $f > a
    grep -Fxvf a b > ex_$f
done


export YALLA_JOB_OUTPUT=__job_submit_dir__/__job_name__.___job_array__.yalla.out
export YALLA_JOB_ERROR=__job_submit_dir__/__job_name__.___job_array__.yalla.err


date  >   $YALLA_JOB_OUTPUT
echo ----------------------------------------------------- >>   $YALLA_JOB_OUTPUT
echo starts of execution on  __PARALLEL_RUNS__ workers with __NB_NODES_PER_PARALLEL_RUNS__ nodes each! >>   $YALLA_JOB_OUTPUT
echo ----------------------------------------------------- >>   $YALLA_JOB_OUTPUT


# building command to be run by yalla...

cat > __yalla_dir__/__job_name__.___job_array__.cmd <<EOF
export nb_task=\$1
task=\`cut -d ' ' -f\$nb_task __yalla_dir__/__job_name__.___job_array__.tasks \`
export worker_rank=\$((\$2-1))
formatted_worker_rank=\$(printf "%04d" \$worker_rank) 
export HOSTS_EXCLUDED=__yalla_dir__/HOSTS/ex___job_name__mach\${formatted_worker_rank}
# export SLURM_ARRAY_JOB_ID=\$SLURM_JOB_ID 
# export SLURM_ARRAY_TASK_ID=\$task
# export SLURM_NTASKS=__NB_CORES_PER_PARALLEL_RUNS__
# export SLURM_PROCS=__NB_CORES_PER_PARALLEL_RUNS__
# export SLURM_STEP_NUM_NODES=__NB_NODES_PER_PARALLEL_RUNS__
# export SLURM_NNODES=__NB_NODES_PER_PARALLEL_RUN
#export SLURM_JOB_NUM_NODES=__NB_NODES_PER_PARALLEL_RUNS__

export YALLA_SRUN_PARAMS="--ntasks=__NB_CORES_PER_PARALLEL_RUNS__ --nodes=__NB_NODES_PER_PARALLEL_RUNS__ "

formatted_task=\$(printf "%04d" \$task)
export PATH=__yalla_exec_dir__:$PATH

cd __job_submit_dir__
. __yalla_dir__/__job_name__.job.__ARRAY__  > __job_output__ 2>  __job_error__ 
EOF
chmod +x __yalla_dir__/__job_name__.___job_array__.cmd

echo __ARRAY_UNFOLD__ > __yalla_dir__/__job_name__.___job_array__.tasks

# computing nodes that will wait work to do

# head -1 __RESULTS_PATH__/LOGS/HOSTS/__job_name__mach* -q > __RESULTS_PATH__/LOGS/__job_name__machines_head.txt


cd __job_submit_dir__

sleep 2s
##srun hostname >> $YALLA_JOB_OUTPUT 2>> $YALLA_JOB_ERROR
nb_runs=$((__PARALLEL_RUNS__+0))
nb_nodes_runs=$((__YALLA_NODES__+0))
echo running srun $YALLA_SRUN_PARAMS -N $((nb_nodes_runs)) -n  $((nb_runs)) --hint=nomultithread --ntasks-per-core=1 --mem_bind=v,local --cpu_bind=threads __yalla_exec_dir__/yalla__DEBUG__.exe '__yalla_dir__/__job_name__.___job_array__.cmd %d' __NB_JOBS__ >> $YALLA_JOB_OUTPUT
srun -N $((nb_nodes_runs)) -n  $((nb_runs)) --hint=nomultithread --ntasks-per-core=1 --mem_bind=v,local --cpu_bind=threads  __yalla_exec_dir__/yalla__DEBUG__.exe '__yalla_dir__/__job_name__.___job_array__.cmd %d %d' __NB_JOBS__ >> $YALLA_JOB_OUTPUT 2>> $YALLA_JOB_ERROR

echo >>   $YALLA_JOB_OUTPUT   
echo ----------------------------------------------------- >>   $YALLA_JOB_OUTPUT   
echo ends of execution on  __PARALLEL_RUNS__ workers __NB_NODES_PER_PARALLEL_RUNS__ nodes each! >>   $YALLA_JOB_OUTPUT
echo ----------------------------------------------------- >>   $YALLA_JOB_OUTPUT   
date >>   $YALLA_JOB_OUTPUT  
